{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting next event: using only activity attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# lazy loading and computation of data\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import collections\n"
   ]
  },
  {
   "source": [
    "## Preprocessing the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"data/financial_log.csv\"\n",
    "txt_file = \"data/financial_log.txt\"\n",
    "delimiter = \":||:\"\n",
    "end_word = \"[EOC]\"\n",
    "ddf = dd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Case ID                         Activity  Resource  \\\n",
       "0   173688             A_SUBMITTED-COMPLETE     112.0   \n",
       "1   173688       A_PARTLYSUBMITTED-COMPLETE     112.0   \n",
       "2   173688           A_PREACCEPTED-COMPLETE     112.0   \n",
       "3   173688  W_Completeren aanvraag-SCHEDULE     112.0   \n",
       "4   173688     W_Completeren aanvraag-START       NaN   \n",
       "5   173688              A_ACCEPTED-COMPLETE   10862.0   \n",
       "6   173688              O_SELECTED-COMPLETE   10862.0   \n",
       "7   173688             A_FINALIZED-COMPLETE   10862.0   \n",
       "8   173688               O_CREATED-COMPLETE   10862.0   \n",
       "9   173688                  O_SENT-COMPLETE   10862.0   \n",
       "\n",
       "        Complete Timestamp      Variant  Variant index lifecycle:transition  \\\n",
       "0  2011-10-01 08:38:44.546  Variant 613            613             COMPLETE   \n",
       "1  2011-10-01 08:38:44.880  Variant 613            613             COMPLETE   \n",
       "2  2011-10-01 08:39:37.906  Variant 613            613             COMPLETE   \n",
       "3  2011-10-01 08:39:38.875  Variant 613            613             SCHEDULE   \n",
       "4  2011-10-01 19:36:46.437  Variant 613            613                START   \n",
       "5  2011-10-01 19:42:43.308  Variant 613            613             COMPLETE   \n",
       "6  2011-10-01 19:45:09.243  Variant 613            613             COMPLETE   \n",
       "7  2011-10-01 19:45:09.243  Variant 613            613             COMPLETE   \n",
       "8  2011-10-01 19:45:11.197  Variant 613            613             COMPLETE   \n",
       "9  2011-10-01 19:45:11.380  Variant 613            613             COMPLETE   \n",
       "\n",
       "             concept:name  AMOUNT_REQ  \n",
       "0             A_SUBMITTED       20000  \n",
       "1       A_PARTLYSUBMITTED       20000  \n",
       "2           A_PREACCEPTED       20000  \n",
       "3  W_Completeren aanvraag       20000  \n",
       "4  W_Completeren aanvraag       20000  \n",
       "5              A_ACCEPTED       20000  \n",
       "6              O_SELECTED       20000  \n",
       "7             A_FINALIZED       20000  \n",
       "8               O_CREATED       20000  \n",
       "9                  O_SENT       20000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Case ID</th>\n      <th>Activity</th>\n      <th>Resource</th>\n      <th>Complete Timestamp</th>\n      <th>Variant</th>\n      <th>Variant index</th>\n      <th>lifecycle:transition</th>\n      <th>concept:name</th>\n      <th>AMOUNT_REQ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>173688</td>\n      <td>A_SUBMITTED-COMPLETE</td>\n      <td>112.0</td>\n      <td>2011-10-01 08:38:44.546</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>A_SUBMITTED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>173688</td>\n      <td>A_PARTLYSUBMITTED-COMPLETE</td>\n      <td>112.0</td>\n      <td>2011-10-01 08:38:44.880</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>173688</td>\n      <td>A_PREACCEPTED-COMPLETE</td>\n      <td>112.0</td>\n      <td>2011-10-01 08:39:37.906</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>A_PREACCEPTED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>173688</td>\n      <td>W_Completeren aanvraag-SCHEDULE</td>\n      <td>112.0</td>\n      <td>2011-10-01 08:39:38.875</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>SCHEDULE</td>\n      <td>W_Completeren aanvraag</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>173688</td>\n      <td>W_Completeren aanvraag-START</td>\n      <td>NaN</td>\n      <td>2011-10-01 19:36:46.437</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>START</td>\n      <td>W_Completeren aanvraag</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>173688</td>\n      <td>A_ACCEPTED-COMPLETE</td>\n      <td>10862.0</td>\n      <td>2011-10-01 19:42:43.308</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>A_ACCEPTED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>173688</td>\n      <td>O_SELECTED-COMPLETE</td>\n      <td>10862.0</td>\n      <td>2011-10-01 19:45:09.243</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>O_SELECTED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>173688</td>\n      <td>A_FINALIZED-COMPLETE</td>\n      <td>10862.0</td>\n      <td>2011-10-01 19:45:09.243</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>A_FINALIZED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>173688</td>\n      <td>O_CREATED-COMPLETE</td>\n      <td>10862.0</td>\n      <td>2011-10-01 19:45:11.197</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>O_CREATED</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>173688</td>\n      <td>O_SENT-COMPLETE</td>\n      <td>10862.0</td>\n      <td>2011-10-01 19:45:11.380</td>\n      <td>Variant 613</td>\n      <td>613</td>\n      <td>COMPLETE</td>\n      <td>O_SENT</td>\n      <td>20000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "ddf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addEOC(df, EOC):\n",
    "    for index, row in df.iterrows():\n",
    "        row['Activity'] = row['Activity'] + EOC\n",
    "    pass\n",
    "\n",
    "def output_to_txt(df):\n",
    "    length = 0\n",
    "    f = open(txt_file, \"w\")\n",
    "    for index, row in df.iterrows():\n",
    "        if (length<=len(row['Activity'])):\n",
    "            length = len(row['Activity'])\n",
    "            max_in = index\n",
    "        listToStr = ':||:'.join(map(str, row['Activity']))\n",
    "        listToStr = listToStr.replace(\" \",\"\")\n",
    "        f.write(listToStr)\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "    return (length, max_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(176, 185548)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "case_grouped = ddf.groupby('Case ID')['Activity'].apply(list,meta=('Activity', 'object')).compute().to_frame()\n",
    "addEOC(case_grouped, [end_word])\n",
    "output_to_txt(case_grouped)\n"
   ]
  },
  {
   "source": [
    "## Word Embedding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _read_words(filename):\n",
    "    with open(filename) as f: \n",
    "        return f.read().replace(\"\\n\", \" \").replace(delimiter, \" \").split()\n",
    "\n",
    "def _build_vocab(filename):\n",
    "  data = _read_words(filename)\n",
    "\n",
    "  counter = collections.Counter(data)\n",
    "  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "  words, _ = list(zip(*count_pairs))\n",
    "  word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "#   # Zippo's test\n",
    "#   import csv\n",
    "#   w = csv.writer(open(\"data/output.csv\", \"w\"))\n",
    "#   for key, val in word_to_id.items():\n",
    "#      w.writerow([key, val])\n",
    "\n",
    "  return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('W_Completerenaanvraag-COMPLETE',\n",
       " 'W_Completerenaanvraag-START',\n",
       " 'W_Nabellenoffertes-COMPLETE',\n",
       " 'W_Nabellenoffertes-START',\n",
       " 'A_PARTLYSUBMITTED-COMPLETE',\n",
       " 'A_SUBMITTED-COMPLETE',\n",
       " '[EOC]',\n",
       " 'W_Nabellenincompletedossiers-COMPLETE',\n",
       " 'W_Nabellenincompletedossiers-START',\n",
       " 'W_Validerenaanvraag-COMPLETE',\n",
       " 'W_Validerenaanvraag-START',\n",
       " 'A_DECLINED-COMPLETE',\n",
       " 'W_Completerenaanvraag-SCHEDULE',\n",
       " 'A_PREACCEPTED-COMPLETE',\n",
       " 'O_CREATED-COMPLETE',\n",
       " 'O_SELECTED-COMPLETE',\n",
       " 'O_SENT-COMPLETE',\n",
       " 'W_Nabellenoffertes-SCHEDULE',\n",
       " 'W_Afhandelenleads-COMPLETE',\n",
       " 'W_Afhandelenleads-START',\n",
       " 'A_ACCEPTED-COMPLETE',\n",
       " 'W_Validerenaanvraag-SCHEDULE',\n",
       " 'A_FINALIZED-COMPLETE',\n",
       " 'W_Afhandelenleads-SCHEDULE',\n",
       " 'O_CANCELLED-COMPLETE',\n",
       " 'O_SENT_BACK-COMPLETE',\n",
       " 'A_CANCELLED-COMPLETE',\n",
       " 'W_Nabellenincompletedossiers-SCHEDULE',\n",
       " 'A_ACTIVATED-COMPLETE',\n",
       " 'A_APPROVED-COMPLETE',\n",
       " 'A_REGISTERED-COMPLETE',\n",
       " 'O_ACCEPTED-COMPLETE',\n",
       " 'O_DECLINED-COMPLETE',\n",
       " 'W_Beoordelenfraude-COMPLETE',\n",
       " 'W_Beoordelenfraude-START',\n",
       " 'W_Beoordelenfraude-SCHEDULE',\n",
       " 'W_Wijzigencontractgegevens-SCHEDULE')"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "_build_vocab(txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a custom standardization function\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(40, 4, input_length=180))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'aclImdb/train'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b0f301753fa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m123\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;34m'aclImdb/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     subset='training', seed=seed)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow2.0\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\text_dataset.py\u001b[0m in \u001b[0;36mtext_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, batch_size, max_length, shuffle, seed, validation_split, subset, follow_links)\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m   file_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[0;32m    140\u001b[0m       \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow2.0\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \"\"\"\n\u001b[0;32m     64\u001b[0m   \u001b[0minferred_class_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[0minferred_class_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'aclImdb/train'"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='training', seed=seed)\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
    "    subset='validation', seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0bfa70ce7f636bef01a6c3e55ef199457d79198d4ae483731f2f9ac3552fc4a7f",
   "display_name": "Python 3.8.8 64-bit ('TensorFlow2.0': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "bfa70ce7f636bef01a6c3e55ef199457d79198d4ae483731f2f9ac3552fc4a7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}